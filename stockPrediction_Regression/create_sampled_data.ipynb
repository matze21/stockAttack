{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beyond_meat_data = pd.read_csv('c:/users/uic33116/documents/hardcodeStockExchange/data/US1.BYND_190513_201011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data = pd.read_csv('c:/users/uic33116/documents/hardcodeStockExchange/data/TSLA_09_30_2020_10_06_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(n_features):\n",
    "    features = []\n",
    "    for i in range(n_features):\n",
    "        features.append(\"feature_t-\"+str(n_features-1-i))\n",
    "        \n",
    "    return features\n",
    "\n",
    "def getHeader(n_features):\n",
    "    features = getFeatures(n_features)\n",
    "    fullHeader = features.copy()\n",
    "    fullHeader.append(\"target\")\n",
    "    return fullHeader\n",
    "\n",
    "def createNormalizedSampledDataAndSafeToCSV(close_timestamped_data, n_features, name):\n",
    "    n_dataPoints        = close_timestamped_data.shape[0]\n",
    "    n_sampledDataPoints = n_dataPoints - n_features - 1\n",
    "    fullHeader          = getHeader(n_features)\n",
    "    \n",
    "    sampledData = np.zeros((n_sampledDataPoints, len(fullHeader)))\n",
    "\n",
    "    for i in range(n_sampledDataPoints):\n",
    "        index = i + n_features\n",
    "        target_index = index + 1\n",
    "        sampledData[i,:] = close_timestamped_data[i:target_index].T / close_timestamped_data[i] \n",
    "        \n",
    "    sampled_data_df = pd.DataFrame(sampledData, columns = [fullHeader])\n",
    "    #sampled_data_df[\"target_absVal\"] = close_timestamped_data[n_features+1 : n_features+1+n_sampledDataPoints] \n",
    "    sampled_data_df[\"normalizeValue\"] = close_timestamped_data[0:n_sampledDataPoints]\n",
    "    \n",
    "    \n",
    "    print(\"safe to directory..\")\n",
    "    sampled_data_df.to_csv('normalized_sampled_data_' + str(name) + '.csv')\n",
    "    print(\"success!\")\n",
    "    \n",
    "    return sampled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample training data\n",
    "n_features = 20   #equals to the datapoints before predicting\n",
    "beyond_meat = beyond_meat_data[\"<CLOSE>\"].to_numpy()\n",
    "tesla = tesla_data[\"Close\"].to_numpy()\n",
    "\n",
    "createNormalizedSampledDataAndSafeToCSV(beyond_meat, n_features, \"beyond_meat\")\n",
    "createNormalizedSampledDataAndSafeToCSV(tesla, n_features, \"tesla\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
